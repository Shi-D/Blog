# 基于GNN的CO问题求解

组合优化问题 Combinatorial optimization (CO)

## 1 背景

近期，图神经网络 (GNN) 作为组合任务的关键构建块的研究激增，直接作为求解器或通过增强精确求解器。 由于 GNN 对排列的不变性和对输入稀疏性的认识，GNN 的归纳偏差有效地编码了组合和关系输入。



## 2 挑战

1. 对图数据进行操作的机器学习方法必须对节点排列保持不变。同时还应该利用**图的稀疏性**。

2. 模型应该区分所提供数据中的关键结构模式，同时可以**扩展到大型现实世界**的实例。

3. 需要考虑附加到节点和边缘的高维向量形式的辅助信息，即**建模目标和附加信息**。

4. 模型应该在**不需要大量标记数据**的情况下理想地工作，并且可以转移到样本外实例。



## 3 解决方法分类

* 监督学习
    * 神经网络
    * 支持向量机
    * boosting

* 无监督学习
    * 自动编码器
    * 聚类
    * 主成分分析

* 强化学习
* 模仿学习
    * 离线
    * 在线
        * on-policy
        * off-policy



## 4 基于 GNN 解决组合优化问题

将 GNN 的变量或约束表示与手工制作的特征相结合的情况并不少见，否则很难用 GNN 自动提取。

### 4.1 在原始方面：寻找可行的解决方案

以下实际场景激发了快速获得高质量可行解决方案的需求。

* 解的质量通常不需要最优性保证
  * 在用户定义的短时间限制内，找到不错的解决方案即可。
* 最优性是需要的，但快速找到一个好的解决方案是当务之急
  * 早期可行的解决方案允许快速决策、提前终止求解器，甚至可以重新审视具有最初被忽略的附加约束的数学模型。



分类和经典论文

* Learning heuristics from scratch 从零开始学习启发式
    * Ptr-Net
        * GNN
        * 缺点：需要接近最优的解决方案作为标签，而 TSP 的最优解很难获得
    * S2V-DQN
        * GNN + DRL
    * Deudon et al. (2018), Nazari et al. (2018), and Kool et al. (2019)
        * 图注意力网络
* Learning hybrid heuristics 学习混合启发式
    * GCN-TreeSearch
        * 优于 S2V-DQN



### 4.2 在双方面：==证明最优性==

除了找到尽可能好的目标值的解决方案之外，CO 中的另一个常见任务是证明给定的解决方案是最优的，或者至少证明找到的最佳目标值与最优目标值之间的差距，称为最优性差距，不大于某个界限。计算这样的界限通常是通过计算优化问题的廉价松弛来实现的。一些工作已经成功地使用 GNN 来指导或增强算法来实现这一目标。因为任务的目标是提供证明（最优性或边界有效性），所以 GNN 通常替换特定算法的组件。



### 4.3 算法推理

**目前使用 GNN 存在的问题：**

对于使用端到端训练的 GNN 解决 CO 问题，Extrapolating 是一个潜在的重要问题。 作为强大推理系统的一个关键特征，它应该适用于任何合理的输入，而不仅仅是训练分布中的输入。 因此，除非我们能够准确地预测将解决的输入类型，否则必须有意义地解决神经网络中的分布外==泛化==问题。



## 5 局限性和研究方向

### 5.1 局限性

* GNN 的表达能力
    * 19 年有大量工作集中于对该局限性的研究，但此类模型通常无法扩展到大图，因此无法在 CO 中使用。
    * 随机初始化的节点特征，但有可能对模型的泛化能力造成影响。
* GNN 的泛化能力
    * GNN 的泛化边界主要取决于图的最大度数、层数、宽度和学习参数矩阵的范数。
    * 而这些边界很大程度上取决于输入图的稀疏性，这表明 GNN 的泛化能力可能会随着图变得越密集而恶化。
* 近似和计算能力
    * 在最小顶点覆盖问题上，一大类 GNN 可实现的最佳近似比为 2，这是次优的。
    * 同时还显示了关于最小支配集问题和最大匹配问题的类似次优结果。

* 较大的推理成本
    * 可以在这些场景之一中采用混合方法，方法是运行一次成熟的 GNN，并使用经过适当训练的 MLP 继续使用 GNN 计算的具有附加特征的嵌入来做出决策。
* 数据限制
    * 任何用于 NP 难题的多项式时间样本生成器都从更简单的子问题中采样。
    * 在某些情况下，这些抽样问题甚至可能是微不足道的。



### 5.2 新研究方向

* 可扩展性、表达性和泛化性三者的折中
    * 当前的 GNN 架构可能会遗漏数据中的关键结构模式，而更具表达性的方法无法扩展到大规模输入。
    * CO 求解器内部的决策（例如分支决策）通常由计算成本低的简单启发式方法驱动。尽管在仅调用几次时可以忽略不计，但与简单的启发式方法相比，在求解器中使用 GNN 进行此类决策是非常耗时的。
    * 求解器内部的计算很难并行化。
* 依赖有限数量的数据
    * 基于机器学习的 CO 求解器的**最终目标是利用先前解决的实例中的知识来更好地解决未来的问题**。
    * 目前许多工作都假设有无限量的数据可用于此目的。
    * 然而，获取无限量标记数据有以下局限，<u>第一</u>在实践中无法进行无限制的标记训练，<u>第二</u>获取标记数据可能具有挑战性。
    * 因此，一个开放的挑战是开发能够有效学习的方法。
* 强化学习的使用
    * 一个明显的绕过标记训练数据需求的方法是**强化学习**。
    * 与监督式方法相比，系统性地使用强化学习来解决 CO 问题才刚刚开始，因为该方法很难训练，并且对哪些强化学习方法适用于 CO 问题知之甚少。
    * 因此，使当前使用的 RL 代理适应 CO 问题的特定需求仍然是另一个关键挑战。
* 为 CO 构建 GNN 的通用实现框架
    * 将 GNN 和机器学习集成到最先进的求解器中很麻烦。
    * 开发一种用于集成从技术细节中抽象出来的 ML 方法的建模语言仍然是一个开放的挑战。



## 6 现成一些 GNN 架构库

有几个文档齐全的开源库用于实现自定义 GNN 架构，提供了大量现成的文献模型。

* PyTorch Geometric

* Deep Graph

* OR-Gym

    * 用于简化机器学习在 CO 中使用的库

* OpenGraphGym

    * OR-Gym 和 OpenGraphGym 都是旨在促进 CO 问题启发式学习的库
    * 界面与流行的 OpenAI Gym 库相似

* MIPLearn

    * 是一个有助于学习 CO 求解器配置参数的库

* Ecole

    * 提供了一个通用的、可扩展的框架，用于实施和评估机器学习增强型 CO。

    * 是基于 OpenAI Gym 的

    * 公开了通用 CO 求解器中出现的几个基本决策任务

    





------

??? note "其他计划"
    该综述中提到的有篇文章对OP问题的监督学习的解具有一定的近似保证，计划阅读该文章</li>
    
    回顾 GCOMB 的工作及其code



 






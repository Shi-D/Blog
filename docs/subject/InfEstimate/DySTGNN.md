# Information Diffusion Prediction via Dynamic Graph Neural Networks

## 0 论文信息

**Author**: Zongmai Cao, Kai Han, Jianfu Zhu

**Conference**: CSCWD' 21 (CCF C)



## 1 背景

现有的研究要么只专注于利用传播路径或利用社交网络，而没有同时考虑两个重要方面：

1. 利用单一来源的信息将减少。
2. 他们没有认识到用户偏好变化的影响。 直觉上，用户感兴趣的内容会随着时间的推移而变化，他或她喜欢的消息可能不再吸引他或她。 因此，考虑用户不断变化的偏好是有益的。



## 2 预备知识

**时间间隔**

将时间轴 $[t_{min}, t_{max}]$ 划分为 $L$ 个时间间隔。

**传播序列**

给定一个在社交网络上传播的信息项 $U$ 的集合。对于每个信息项 $i \in U$，都有一个传播序列 $s_i = {(v_1, t_{v_1})), ..., (v_T , t_{v_T} )}$，用 $idx_v$ 代表时间戳 $t_v$ 属于哪个时间间隔，用 $Lookup(·)$ 函数进行计算，$idx_v = Lookup(t_v)$。

因此，重写传播序列为，$s_i = \{(v_1 , idx_{v_1} ), ..., (v_T , idx_{v_T})\}$。

**扩散图**

传播项 $i$ 的在第 $K$ 个时间间隔的传播图为 $D_i(k) = \{V,E_i(k)\}$，其中 $E_i(k) = \{(u,v)|(u,v) ∈ E,t_u < t_v,idx_u ≤ idx_v = k\}$。

为了更好地表征用户的动态偏好，我们将所有信息项视为一个整体，使用所有扩散序列一起构建扩散图。第 $K$ 个时间间隔的扩散图记为 $D(k) = \{V,E(k)\}$，沿时间线的一系列扩散图快照记为 $D = \{D(k)|k = 1， 2, ..., L\}$。

**问题定义**

给定一个社交图 $G$ 和所有信息项扩散序列 $S = {s_i|∀i ∈ U}$，学习一个扩散预测模型 $M$，它能够预测下一个将被感染的用户，即 $v_k$，当给定扩散序列 $s = {(v_1, t_1), ..., (v_{k-1}, t_{k-1})}$。



## 3 DySTGNN模型

DySTGNN 有两个主要构建块，（1）时间注意块和（2）结构聚合块。

### 3.1 时间注意块

时间注意块旨在生成用于预测下一个受感染用户的时间上下文。时间上下文应该利用扩散图在时间间隔内表征用户的偏好。

时间注意块由扩散路径注意层和掩蔽位置感知注意层和用户组合层组成，如图所示。

**扩散路径注意力层**捕获用户之间的交互，为每个用户生成偏好嵌入，代表用户在当前时间间隔内的偏好。

**掩码位置感知注意力层**聚合来自不同时间间隔的偏好嵌入，从而产生表征用户偏好演变的时间嵌入。

**用户组合层**融合了来自不同时间间隔的用户的时间嵌入，以生成预测下一个受感染用户的上下文。根据给定的扩散序列，选择用户嵌入的时间间隔取决于用户的感染时间。我们将在下面详细描述这三层。

![DySTGNN-1](./DySTGNN-1.png)

#### 3.1.1 扩散路径注意力层

**输入1**

扩散图 $D = \{D(k)|k = 1, 2, ..., L\}$，用 $A^k$ 来表示 $D(k)$ 的邻接矩阵。

归一化边权重使得 $\sum_{􏰁(u,v)∈E(k)} A^k(u, v) = 1$

**输入2**

用户的偏好嵌入 $\{z_v^l ∈ R^{d_z} , ∀v ∈ V, l = 1, ..., L\}$，其中 $d_z$ 是嵌入的维度。 嵌入可以设置为节点属性或由正态分布随机初始化。

**GAT**

将扩散路径注意层设置为 GAT 的变体。GAT 可以作为聚合器，使用注意机制对邻居嵌入的贡献进行不同的加权。

$f^k_{uv} = σ(A^k(u,v)·a^T[W^sz^k_u||W^sz^k_v]),∀(u,v)∈E(k)$

$\alpha_{uv}^k = \frac{exp(f^k_{uv})}{\sum_{(w,v) \in E(k)}exp(f^k_{wv})}$

$z_v^k = \sigma (\sum_{(u,v) \in E(k)} \alpha_{uv}^k W^sz^k_u)$

其中，$W^s ∈ R^{{d_s}×d}$，$α ∈ R^{2d_s}$，系数 $α_{uv}$ 暗示节点 $u$ 在当前时间间隔内对激活节点 $v$ 的贡献。



#### 3.1.2 掩码位置感知注意力层

为了进一步捕捉相邻扩散图之间的扩散演化模式，设计了一个掩码位置感知注意力层。

**输入**

节点 $v$ 的一系列偏好嵌入，记为 $\{z_v^1, z_v^2, ..., z_v^L\}, z_v^k ∈ R^{d_s}$，是扩散路径注意力层的输出。

将其堆叠为矩阵，$Z_v ∈ R^{L×{d_s}}$

**输出**

每个节点 $v$ 的时间嵌入序列，表示为 $\{e^1_v,e^2_v,...,e^L_v\},e^k_v ∈R^{d_e}$

将其堆叠为矩阵，$E_v ∈ R^{L×d_e}$

**GAT**

使用 $z_t$ 作为查询向量来参与 $\{z_{t^′}, t^′ < t\}$，表征跨时间间隔的偏好演变。将查询、键和值转换矩阵定义为 $W_q ∈ R^{d_s×d_e}, W_k ∈ R^{d_s×d_e}, W_v ∈ R^{d_s×d_e}$

为了切断未来时间间隔的干扰，添加了一个掩码矩阵 $M ∈ R^{L×L}$ 来关注直到 $t$ 的所有时间间隔。

公式如下：

$a_v^{ij} =(\frac{((Z_vW_q)(Z_vW_k)^T)_{ij}}{\sqrt{d_e}} + M_{ij})$，$M_{ij} = \begin{cases} 0,  & i \leq j \\ -\infty, & \text{otherwise} \end{cases}$

$\beta_v^{ij} = \frac{exp(a_v^{ij})}{\sum_{k=1}^T a_v^{ik}}$

$E_v = \beta_v(Z_vW_v)$



#### 3.1.3 用户组合层

根据实际经验，最近被感染的用户更有可能感染其他用户。 因此，我们融合了查询序列 s 的最后 m 个用户，即 $\{v_{k-m}, v_{k-m-1}, ..., v_{k-1}\}$。用于预测 $v_k$ 的时间上下文，其中 $m$ 是表示观察窗口大小的超参数。

将上下文表示为 $e_{agg}$，它结合了用户到级联的重要性和时间衰减效应。

为了显式注入时间间隔信息，采用位置嵌入，使用 $pos_{v_i} ∈ R^{d_p}$ 来表示 $t_{v_i}$ 属于哪个时间间隔。 $e^{agg}$ 的公式定义如下： $∀i∈\{k−m,...,k−1\}, idx_{v_i} =Lookup(t_{v_i})$

$\gamma_i = \frac{exp(w^T elu(W_c(e_{v_i}^{idx_{v_i}}||pos_{v_i})+b_c))}{\sum_{j=k-m}^{k-1} exp(w^Telu(W_c(e_{v_j}^{idx_{v_j}}||pos_{v_j})+b_c))}$

其中，$W_c ∈ R^{{d_c}×(d_e+d_p)}, w,b_c ∈ R^{d_c},elu$ 是非线性激活函数。

则，$e^{agg} = \sum_{i=k−m}^{k-1} γ_ie_{v_i}^{idx_{v_i}}$



#### 3.1.4 实现细节

1. 因为在每个时间间隔内只会将一小部分边添加到扩散图中，通过稀疏矩阵实现时间注意块。这样可以避免不必要的计算，大大提高效率。
2. 采用多头注意力来提高模型容量和稳定性。



### 3.2 结构聚合

结构聚合块旨在将局部结构模式聚合到节点的结构嵌入中。该块的输入是社交图 $G = (V, E)$ 的邻接矩阵 $A$ 和结构嵌入矩阵 $S ∈ R^{n×d_{st}}$，其中 $n = |V|$，$d_{st}$ 是初始节点结构向量的维数。

采用图卷积网络（GCN）的变体来聚合邻居的特征。

聚合所有邻居的嵌入可能会导致嵌入过于平滑，并且不适用于实践中的大图。因此，从 $v$ 及其第 $l$ 层的邻居 $N(v)$ 中采样 $z_l$ 个用户 $\{u_1,u_2,...,u_{z_l}\}$。

在具体实现中，使用了两层 GCN 并设置 $l_1 = 5, l_2 = 10$。

则，$s^{agg} =mean\{s_{v_{k−m}},...,s_{v_{k−1}}\}$



### 3.3 预测和训练

给定扩散序列 $s = {(v_1,t_1),...,(v_{k−1},t_{k−1})}$，预测下一个感染用户 $v_k$。 第 $k$ 个感染用户的概率计算为,

$p_k =softmax(W_p ·concat(e^{agg},s^{agg})+b_p)$

其中，$p_k ∈ R|V|$，$p_k[v]$ 表示节点 $v$ 是第 $k$ 个被感染的概率。

扩散预测的训练目标是最大化所有训练扩散序列的对数似然，

$J(\theta) = \sum_{i=1}^C \sum_{k=1}^{|c_i|-1} log(p_k^i[v_{k+1}^i])$

其中 $C$ 是所有扩散序列的数量，$v_i$ 表示第 $i$ 个扩散序列中真正的第 $(k + 1)$ 个节点，$Θ$ 表示模型中的所有参数。



## 4 实验

### 4.1 实验设置

**数据集**

 <img src="../DySTGNN-2.png" alt="DySTGNN-2" style="zoom:30%;" />

**Baselines**

• CYAN-RNN：采用基于注意力的RNN 来捕获扩散序列中的交叉依赖性，其中扩散序列被建模为扩散树。
• TopoLSTM：通过将隐藏状态构建为有向无环图来扩展普通 LSTM 模型，以学习用于扩散预测的拓扑感知用户嵌入。
• DeepDiffuse：采用注意机制和嵌入方法来合并感染时间戳。该模型可以根据先前观察到的信息扩散序列预测下一次感染的时间和对象。
• NDM：采用自注意力和卷积神经网络来缓解长期依赖问题，以实现更高的预测精度。
• SNIDSA：采用门控机制来扩展 RNN 方法，该方法能够利用所有用户对的成对相似性和结构信息。
• FOREST：是结合强化学习框架的多尺度扩散预测模型。该模型采用基于RNN的方法作为微观模型，采用强化学习作为宏观模型。它实现了最先进的性能。

• DySTGNN-S：是只有结构聚合的模型化块。

• DySTGNN-T 是只有时间注意块的模型。

**参数设置**

各种参数设置略。



### 4.2 实验结果

1. 与基于扩散路径的方法（包括 CYAN-RNN、TopoLSTM、DeepDiffuse 和 NDM）相比，DySTGNN 在 Hits@10 上实现了超过 4% 的改进，在 Hits@100 上实现了超过 8% 的改进。该预测还在所有 Map@k 上实现了约 2% 的绝对改进。这些方法主要将扩散路径建模为序列或图结构，完全忽略了社会关系。实验结果证明，考虑用户社交网络进行信息扩散预测是有效的。

2) 与 SNIDSA 和 FOREST 相比，DySTGNN 始终表现更好。这三种方法都利用社会关系和传播记录来促进传播预测。然而，SNIDSA 和 FOREST 仅将扩散序列建模为序列数据，不足以反映用户的动态偏好。 DySTGNN 的改进证明了引入动态扩散图的必要性。
3) 与所有其他方法相比，DySTGNN-S 始终是最差的，因为我们只是根据最近 m 个用户的结构嵌入进行扩散预测，这根本无法捕获扩散序列背后的时间特征。 DySTGNN-T 的性能始终优于 CYAN-RNN、TopoLSTM、DeepDiffuse 和 NDM，这验证了对用户动态偏好建模的有效性。 DySTGNN 与 DySTGNN-T 相比的改进也验证了纳入社会关系信息的必要性。

 <img src="../DySTGNN-3.png" alt="DySTGNN-3" style="zoom:35%;" />